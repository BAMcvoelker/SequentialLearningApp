{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Learning App for Materials Discovery - *SLAMD*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from ipywidgets import Box,Label,Text,FloatText,BoundedFloatText,Checkbox,ToggleButtons,Dropdown,VBox,HBox,Accordion,BoundedIntText,SelectMultiple,RadioButtons,FloatRangeSlider,Button,IntSlider,Label,Tab,Output,FileUpload,Layout,FloatSlider\n",
    "from IPython.display import display,Markdown,HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as SKRFR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn import preprocessing\n",
    "from lolopy.learners import RandomForestRegressor\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)   \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tab\n",
    "tab =Tab() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputs\n",
    "out=Output()\n",
    "out_plotting=Output()\n",
    "out_settings=Output()\n",
    "out_algo=Output()\n",
    "out_perform_experiment=Output()\n",
    "out_input_space=Output()\n",
    "out_res=Output()\n",
    "out_iter_aut=Output()\n",
    "out_results_SL=Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Upload\n",
    "up = FileUpload(accept=\"\", multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload Properties \n",
    "delim =RadioButtons(\n",
    "    options=[';', ','],\n",
    "    description='Separator: ',\n",
    "    disabled=False)\n",
    "delim_dec = RadioButtons(\n",
    "    options=[',', '.'],\n",
    "    description='Decimal delim: ',\n",
    "    disabled=False)\n",
    "\n",
    "eraser = SelectMultiple(\n",
    "    options=['tab','\"',\"%\"],\n",
    "    value=['tab'],\n",
    "    #rows=10,\n",
    "    description='Eraser: ',\n",
    "    disabled=False)\n",
    "rows = IntSlider(\n",
    "    value=0,\n",
    "    step=1,\n",
    "    description='# of lines:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Info \n",
    "toggle = ToggleButtons(\n",
    "    options=['Preview  ', 'Info  ', 'Stats  '],\n",
    "    description='Options',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    icons=['search', 'info', 'tachometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of Targets and Features\n",
    "feature_selector=SelectMultiple(\n",
    "    options=[],\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')) \n",
    "target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "fixed_target_selection=SelectMultiple(\n",
    "    options=[],\n",
    "    placeholder='Select the target variable',\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "selector_plot_variable=SelectMultiple(\n",
    "    options=[],\n",
    "    description='Features',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "graph_type = Dropdown(\n",
    "    options=['Choose graph type','Scatter', 'Scatter Matrix', 'Correlation Heatmap'],\n",
    "    value='Choose graph type',\n",
    "    description='Graph type:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "x_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='X-Axis:',\n",
    "    disabled=False)\n",
    "y_axis = Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False)\n",
    "\n",
    "select_x=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select X-axis',\n",
    "    description='X-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_y=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select Y-axis',\n",
    "    description='Y-Axis:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_hue=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the hue',\n",
    "    description='Hue:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_size=Dropdown(\n",
    "    options=[''],\n",
    "    value='',\n",
    "    placeholder='select the size',\n",
    "    description='Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "container_checkboxes_targets=VBox([])\n",
    "container_checkboxes_fixed_targets=VBox([])\n",
    "\n",
    "container_slider_targets=VBox([])\n",
    "container_slider_fixed_targets=VBox([])\n",
    "\n",
    "box_targets=VBox([])\n",
    "box_fixed_targets=VBox([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Learning Properties\n",
    "select_strategy=Dropdown(\n",
    "    options=['MEI (exploit)','MU (explore)','MLI (explore & exploit)','MEID (exploit)','MLID (explore & exploit)'],\n",
    "    value='MEI (exploit)',\n",
    "    placeholder='select the strategy',\n",
    "    description='Strategy:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "select_model=Dropdown(\n",
    "    options=['lolo Random Forrest (RF) - quick (requ. min 8 init. samples)','Decision Trees (DT) - quick','Random Forrest (RFscikit) - quick','Gaussian Process Regression (GPR) - quick'],\n",
    "    value='Decision Trees (DT) - quick',\n",
    "    placeholder='select the Model',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Buttons\n",
    "button_confirm_strategy=Button(\n",
    "    description='Confirm strategy ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected strategy',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_upload =Button(\n",
    "    description='Upload',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to Upload',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_preview = Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to preview',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_plot = Button(\n",
    "    description='Plot',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Click to Plot',\n",
    "    icon='pencil',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "button_show_DS=Button(\n",
    "    description='Visualize settings',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Plots Design space in TSNE coordinates with candidates and colored targets',\n",
    "    icon='search',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_confirm_plot_var=Button(\n",
    "    description='Confirm selection',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm the selected target variable',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "button_plot_comparision=Button(\n",
    "    description='Compare',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Simplify the Columns',\n",
    "    icon='fa-bar-chart',\n",
    "    layout=Layout(width='50%'))\n",
    "\n",
    "button_confirm_options=Button(\n",
    "    description='Confirm options ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm options',\n",
    "    icon='check',\n",
    "    layout=Layout(width='50%',height ='inherit'))\n",
    "                           \n",
    "button_perform_experiment=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "run_button_aut_template=Button(\n",
    "    description='Run',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Perform Experiment',\n",
    "    icon='fa-calculator',\n",
    "    layout=Layout(width='100%'))\n",
    "\n",
    "confirm_import_button=Button(\n",
    "    description='Confirm import ',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Confirm selected Strategy',\n",
    "    icon='check',\n",
    "layout=Layout(width='50%',height ='inherit'))\n",
    "\n",
    "preview_settings_button=Button(\n",
    "    description='Preview',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Click to Preview',\n",
    "    icon='search',\n",
    "layout=Layout(width='50%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Layout File Upload Tab\n",
    "\n",
    "accordion = Accordion(children=[\n",
    "    up, \n",
    "    HBox([delim, delim_dec, eraser]), \n",
    "    rows])\n",
    "\n",
    "accordion.set_title(0, 'File Selection')\n",
    "accordion.set_title(1, 'Delimiter')\n",
    "accordion.set_title(2, 'Skip Rows')\n",
    "\n",
    "\n",
    "accordion_box = VBox([\n",
    "    accordion, \n",
    "    HBox([button_preview, button_upload ]),\n",
    "    out\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Tab\n",
    "\n",
    "container_plot_options= VBox([])\n",
    "button_container=HBox([button_plot])\n",
    "\n",
    "plotting=VBox(children=[VBox( [\n",
    "        HBox([graph_type]),\n",
    "        container_plot_options,\n",
    "        button_container,\n",
    "        out_plotting\n",
    "        ]\n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sequential Learning Tab \n",
    "\n",
    "slider_of_for_dist=FloatSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Prediction quantile for distance-based utility (smaller values recommended for weak predictors).:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "slider_of_for_std=FloatSlider(\n",
    "    value=1,\n",
    "    min=0.1,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    description='σ Factor (to controll the weigth of uncertainty):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "quantile_tar_slider= FloatSlider(\n",
    "    value=100,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Target threshold (Quantile):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    \n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "initial_sample_size_text=BoundedIntText(\n",
    "    value=4,\n",
    "    min=2,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Initial Sample Size:',\n",
    "    disabled=False,\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "box_features_slider=VBox([])\n",
    "\n",
    "\n",
    "plottingDS=VBox(children=[VBox( [\n",
    "        \n",
    "        out_input_space\n",
    "    ]\n",
    ")])\n",
    "\n",
    "DataPre_sl=VBox([\n",
    "        HBox([Label('Feature Selection',layout=Layout(width='50%', height='80px')),(feature_selector)]),\n",
    "        HBox([Label('Target Selection',layout=Layout(width='50%', height='80px')),target_selection]),\n",
    "        box_targets,\n",
    "        HBox([Label('Fixed Target Selection',layout=Layout(width='50%', height='80px')),fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "        HBox([quantile_tar_slider]),\n",
    "        HBox([initial_sample_size_text,button_show_DS]),\n",
    "        plottingDS    \n",
    "])\n",
    "\n",
    "\n",
    "    \n",
    "DataPre=VBox([\n",
    "        HBox([feature_selector]),\n",
    "        HBox([target_selection]),\n",
    "        box_targets,\n",
    "        HBox([fixed_target_selection]),\n",
    "        box_fixed_targets,\n",
    "       ])\n",
    "\n",
    "iterations=IntSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='# of SL runs:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    layout=Layout(width='50%')\n",
    ")\n",
    "\n",
    "custom_container=VBox([HBox([])])\n",
    "results_container=VBox([HBox([])])\n",
    "strategy_container=HBox([select_strategy, button_confirm_strategy ])\n",
    "\n",
    "start_and_stop_sl_container=HBox([button_perform_experiment])\n",
    "\n",
    "sl_settings= VBox([\n",
    "    strategy_container,\n",
    "    custom_container,\n",
    "    HBox([select_model,iterations]),\n",
    "    start_and_stop_sl_container,\n",
    "    out_perform_experiment,\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "sl_results= VBox([\n",
    "    out_results_SL\n",
    "])\n",
    "\n",
    "\n",
    "sl_accordion=Accordion(children=[DataPre_sl,sl_settings,sl_results])\n",
    "sl_accordion.set_title(0,\"Settings\")\n",
    "sl_accordion.set_title(1,\"Sequential Learning Parameters\")\n",
    "sl_accordion.set_title(2,\"Results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layout Tabs\n",
    "\n",
    "children = [\n",
    "    accordion_box, \n",
    "    VBox([toggle, out]),\n",
    "    plotting,\n",
    "    sl_accordion,\n",
    "    \n",
    "    \n",
    "   ]\n",
    "\n",
    "tab.children = children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Naming Tabs\n",
    "\n",
    "tab.set_title(0, \"Upload\")\n",
    "tab.set_title(1, \"Data Info\")\n",
    "tab.set_title(2, \"Design Space Explorer\")\n",
    "tab.set_title(3, \"Sequential Learning\")\n",
    "tab.set_title(4, \"Automation 🤖\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Utility Methods\n",
    "def decide_max_or_min(source,columns,dataframe):\n",
    "        row_list=[source.children[decide].children[0].value for decide in range(len(columns))]\n",
    "        for goal in row_list:\n",
    "                        for column in columns:\n",
    "                            if (goal == \"minimize\"):\n",
    "                                dataframe[column]=dataframe[column]*(-1)\n",
    "                              \n",
    "                                \n",
    "                                \n",
    "def extend(list_of_2dms_arrays_to_extend):\n",
    "    np_array=np.array(list_of_2dms_arrays_to_extend)\n",
    "    max_cols=max(map(len,np_array))\n",
    "    result_list=[]\n",
    "    for i in np_array:\n",
    "                    if(len(i) == max_cols):\n",
    "                        result_list.append(i)\n",
    "                    elif (len(i) != max_cols):\n",
    "                        how_often=max_cols-len(i)\n",
    "                        matrix_to_extend=np.tile(i[:][-1], (how_often, 1))\n",
    "                        i=np.concatenate((i, matrix_to_extend))\n",
    "                        result_list.append(i)\n",
    "                    \n",
    "   \n",
    "    return result_list\n",
    "\n",
    "    \n",
    "           \n",
    "def flatten_list(nested_list):\n",
    "    for sublist in nested_list:\n",
    "        flatlist=[element for element in sublist]  \n",
    "    return flatlist\n",
    "\n",
    "\n",
    "def import_settings():\n",
    "    content= content_parser(import_button)\n",
    "    settings = pd.read_csv(content, sep=',', index_col=False, decimal='.')\n",
    "         \n",
    "    return settings\n",
    "\n",
    "\n",
    "def content_parser(source):\n",
    "    if source.value == {}:\n",
    "        \"\"\"with out:\n",
    "            out.clear_output\n",
    "            display(Markdown('No CSV loaded'))\n",
    "            #print('No CSV loaded')    \"\"\"\n",
    "    else:\n",
    "        from io import StringIO\n",
    "        typ, content = \"\", \"\"\n",
    "        up_value = source.value\n",
    "        for i in up_value.keys():\n",
    "            typ = up_value[i][\"metadata\"][\"type\"]\n",
    "            if typ == \"text/csv\" or typ == \"application/vnd.ms-excel\":\n",
    "                content = up_value[i][\"content\"]\n",
    "                content_str = str(content, 'utf-8')\n",
    "\n",
    "                if eraser.value != {}: \n",
    "                    for val in eraser.value:\n",
    "                        if val == \"tab\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        elif val ==\"%\":\n",
    "                            content_str = content_str.replace(\"\\t\",\"\")\n",
    "                        else:\n",
    "                            content_str = content_str.replace(val,\"\")\n",
    "                if content_str != \"\":\n",
    "                    str_io = StringIO(content_str) \n",
    "                    return str_io\n",
    "def df_converter():\n",
    "    content = content_parser(up)\n",
    "    if content is not None:\n",
    "            df = pd.read_csv(content, sep=delim.value, index_col=False, skiprows=rows.value,decimal=delim_dec.value)\n",
    "            df=df.apply(pd.to_numeric,errors=\"ignore\")\n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "            return df\n",
    "    else:\n",
    "        return None\n",
    "def preview():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is your data:'))\n",
    "        \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "            \n",
    "def upload():\n",
    "    \n",
    "    df = df_converter()\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        display(Markdown('This is how your uploaded data looks like:'))\n",
    "       \n",
    "        if df is not None:\n",
    "            display(Markdown(df.head(10).to_markdown()))\n",
    "            x_axis.options = df.columns\n",
    "            y_axis.options = df.columns\n",
    "            feature_selector.options= df.columns\n",
    "            \n",
    "            select_x.options=df.columns\n",
    "            select_y.options=df.columns\n",
    "            select_size.options=df.columns\n",
    "            select_hue.options=df.columns\n",
    "            selector_plot_variable.options=df.columns\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            display(Markdown('Configuration is wrong/missing...'))\n",
    "\n",
    "            \n",
    "            \n",
    "def create_download_link( df, title, filename): \n",
    "    import base64\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = html_buttons = '''<html>\n",
    "    <head>\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    </head>\n",
    "    <body>\n",
    "    <a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" download>\n",
    "    <button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-warning\">{title}</button>\n",
    "    </a>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    html_button = html_buttons.format(payload=payload,filename=filename,title=title)\n",
    "    return HTML(html_button)\n",
    "\n",
    "            \n",
    "            \n",
    "def desc():\n",
    "    info_level = toggle.value\n",
    "    if info_level != {}:\n",
    "        df = df_converter()\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown('\\n Data {} \\n'.format(\n",
    "                info_level)))\n",
    "            if df is not None:\n",
    "                if info_level == 'Info  ':\n",
    "                    df.info()\n",
    "                elif info_level == 'Stats  ':\n",
    "                    display(Markdown(df.describe().to_markdown()))\n",
    "                elif info_level == 'Preview  ':\n",
    "                    display(Markdown(df.head(10).to_markdown()))\n",
    "                else:\n",
    "                    display(Markdown('Configuration is wrong/missing...'))\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Methods\n",
    "import seaborn as sns\n",
    "\n",
    "def plot():\n",
    "    graph = graph_type.value\n",
    "    if graph==\"Scatter\":\n",
    "        plot_scatter()\n",
    "    elif graph==\"Correlation Heatmap\":\n",
    "            plot_heat()\n",
    "    elif graph==\"Scatter Matrix\":\n",
    "            plot_pairwise()\n",
    "          \n",
    "        \n",
    "def plot_pairwise():\n",
    "    df =confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        sns.pairplot(df)\n",
    "        plt.show()\n",
    "\n",
    "def plot_heat():\n",
    "    df = confirm_var()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        corr = df.corr()\n",
    "        plt.figure(figsize=(12,7))\n",
    "        sns.heatmap(corr, annot=True, cmap='Blues')\n",
    "        b, t = plt.ylim()\n",
    "        plt.ylim(b+0.5, t-0.5)\n",
    "        plt.title(\"Feature Correlation Heatmap\")\n",
    "        plt.show()\n",
    "            \n",
    "def plot_scatter():\n",
    "    data=df_converter()\n",
    "    with out_plotting:\n",
    "        out_plotting.clear_output()\n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "        #not generic\n",
    "        sns.scatterplot(y=select_y.value, x=select_x.value, hue=select_hue.value, size=select_size.value, data=data, ax=ax, sizes=(50, 300))\n",
    "        ax.set_title(select_y.value+ \"vs\"+ select_x.value)\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "        plt.show()\n",
    "        plt.close(fig)  \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def confirm_options():\n",
    "    items=box_features_slider.children\n",
    "    df = df_converter()\n",
    "    Y = df.loc[:,df.columns.isin(target_selection.value)]\n",
    "    \n",
    "    for slider in items:\n",
    "            unt_grenz= slider.value[0]/100\n",
    "            ob_grenz= slider.value[1]/100\n",
    "            Y = Y[(Y >= Y.quantile(unt_grenz) ) & (Y <= Y.quantile(ob_grenz))]\n",
    "            Y= Y.dropna()\n",
    "    \n",
    "    return Y   \n",
    "\n",
    "\n",
    "def confirm_features():\n",
    "    df = df_converter()\n",
    "    train = feature_selector.value\n",
    "    target_selection.options=df.columns[~df.columns.isin(feature_selector.value)]\n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(target_selection.value)& ~df.columns.isin(feature_selector.value)]\n",
    "    train = df.columns[df.columns.isin(feature_selector.value)]\n",
    "    return train\n",
    "\n",
    "\n",
    "def confirm_var():\n",
    "    df= df_converter()\n",
    "    selection = list(selector_plot_variable.value)\n",
    "    var = df[selection]\n",
    " \n",
    "    return var\n",
    "\n",
    "  \n",
    "def confirm_target():\n",
    "    \n",
    "    df = df_converter()\n",
    "    target = df.columns[df.columns.isin(target_selection.value)]\n",
    "    fixed_target_selection.options=df.columns[~df.columns.isin(target_selection.value)& ~df.columns.isin(feature_selector.value)]\n",
    "\n",
    "    \n",
    "    return target \n",
    "\n",
    "def confirm_fixed_target():\n",
    "    df = df_converter()\n",
    "    fixed_target = df.columns[df.columns.isin(fixed_target_selection.value)]\n",
    "    return fixed_target\n",
    "\n",
    "def confirm_strategy():\n",
    "    strategy= select_strategy.value\n",
    "    if strategy != {}:\n",
    "            custom_container.children=[]\n",
    "            return select_strategy.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slider_for_dist_quantile():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist,  button_confirm_strategy]\n",
    "    \n",
    "def create_slider_for_dist_quantile_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_dist, slider_of_for_std,  button_confirm_strategy]\n",
    "        \n",
    "def create_slider_for_std():\n",
    "    strategy_container.children=[select_strategy,slider_of_for_std,  button_confirm_strategy]\n",
    "    \n",
    "def create_dynamically_checkboxes(targets):\n",
    "    radiobuttons = [RadioButtons(\n",
    "    options=['maximize', 'minimize'],\n",
    "    value='maximize', \n",
    "    description=feature,\n",
    "    disabled=False\n",
    "    )\n",
    "    for feature in targets]\n",
    "    \n",
    "    checkboxes = [Checkbox(\n",
    "    value=False,\n",
    "    description='Check to use treshhold',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    slider = [FloatText(\n",
    "    value=np.max(df_converter()[feature].to_numpy()),\n",
    "    continuous_update=True,\n",
    "    description=feature,\n",
    "    disabled=False)\n",
    "    \n",
    "    for feature in targets]\n",
    "    \n",
    "    \n",
    "    slider_np=np.array(slider)\n",
    "    radiobuttons_np=np.array(radiobuttons)\n",
    "    checkboxes_np=np.array(checkboxes)\n",
    "    \n",
    "    return radiobuttons_np,slider_np,checkboxes_np\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(columns=['Requ. experiments (mean)','Requ. experiments (std)','Requ. experiments (90%)',\n",
    "                                  'Requ. experiments (max)','Algorithm','Utlity Function','σ Factor','5 cycle perf.','10 cycle perf.',\n",
    "                                  'qant. (distance utility)','# SL runs','Initial Sample','# of samples in the DS',\n",
    "                                  '# Features','# Targets', 'Target threshold','Sample threshold','Features name','Targets name',\n",
    "                                  'Req. experiments (all)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "class targets():\n",
    "    checkboxes=None\n",
    "    radiobuttons=None\n",
    "    slider=None\n",
    "    not_stand_df=None\n",
    "    idx=None\n",
    "\n",
    "    def __init__(self,container,selection):\n",
    "        self.container=container\n",
    "        self.selection=selection\n",
    "        \n",
    "    def on_selection_change(self,change):\n",
    "        confirm_target()\n",
    "        self.not_stand_df=df_converter()\n",
    "        self.container.children=()\n",
    "        selection_as_list=list(self.selection.value)\n",
    "        self.radiobuttons,self.slider,self.checkboxes=create_dynamically_checkboxes(selection_as_list)\n",
    "        \n",
    "        for row in range(len(self.radiobuttons)):\n",
    "            \n",
    "            self.container.children=(*self.container.children,HBox([self.radiobuttons[row],self.checkboxes[row],self.slider[row]]))\n",
    "            self.checkboxes[row].observe(functools.partial(self.on_checkbox_checked,row),names='value')\n",
    "            self.slider[row].observe(functools.partial(self.on_texfield_typed,row),names='value')\n",
    "     \n",
    "    def on_texfield_typed(self,row,change):\n",
    "        \n",
    "        self.checkboxes[row].value=False\n",
    "        \n",
    "    def on_checkbox_checked(self,row,change):\n",
    "        \n",
    "        if(self.checkboxes[row].value==True):\n",
    "            \n",
    "            \n",
    "            selection_as_list=list(self.selection.value)\n",
    "            max_df=np.max(df_converter()[selection_as_list[row]].to_numpy())\n",
    "            min_df=np.min(df_converter()[selection_as_list[row]].to_numpy())\n",
    "               \n",
    "            \n",
    "            \n",
    "            \n",
    "            if(self.slider[row].value>max_df):\n",
    "                self.slider[row].value=max_df\n",
    "            \n",
    "            if(self.slider[row].value < min_df):\n",
    "                self.slider[row].value=min_df\n",
    "                \n",
    "            # debug print(self.slider[row].value)\n",
    "            df_mask=self.not_stand_df[selection_as_list[row]]>=self.slider[row].value\n",
    "            temp=self.not_stand_df\n",
    "            \n",
    "            if(len(temp[df_mask])==0):\n",
    "                print(\"selection false,max min for this feature in this combination is: or change other targets\")\n",
    "            else:\n",
    "                temp = self.not_stand_df[df_mask]\n",
    "                self.idx = temp[df_mask].index\n",
    "                #print(\"len idx in on slider change\",len(self.idx))\n",
    "                \n",
    "        \n",
    "\n",
    "class fixed_targets(targets):\n",
    "    checkboxes=None\n",
    "    radiobuttons=None\n",
    "    slider=None\n",
    "    not_stand_df=None\n",
    "    idx=None\n",
    "\n",
    "    def __init__(self,container,selection):\n",
    "        self.container=container\n",
    "        self.selection=selection\n",
    "        \n",
    "    def on_selection_change(self,change):\n",
    "        \n",
    "        confirm_fixed_target()\n",
    "        self.not_stand_df=df_converter()\n",
    "        self.container.children=()\n",
    "        selection_as_list=list(self.selection.value)\n",
    "        self.radiobuttons,self.slider,self.checkboxes=create_dynamically_checkboxes(selection_as_list)\n",
    "        \n",
    "        for row in range(len(self.radiobuttons)):\n",
    "            \n",
    "            self.container.children=(*self.container.children,HBox([self.radiobuttons[row],self.checkboxes[row],self.slider[row]]))\n",
    "            self.checkboxes[row].observe(functools.partial(self.on_checkbox_checked,row),names='value')\n",
    "            self.slider[row].observe(functools.partial(self.on_texfield_typed,row),names='value')\n",
    "    def on_texfield_typed(self,row,change):\n",
    "        \n",
    "        self.checkboxes[row].value=False\n",
    "        \n",
    "    def on_checkbox_checked(self,row,change):\n",
    "        \n",
    "        if(self.checkboxes[row].value==True):\n",
    "            \n",
    "            \n",
    "            selection_as_list=list(self.selection.value)\n",
    "            max_df=np.max(df_converter()[selection_as_list[row]].to_numpy())\n",
    "            min_df=np.min(df_converter()[selection_as_list[row]].to_numpy())\n",
    "            \n",
    "            \n",
    "            if(self.slider[row].value>max_df):\n",
    "                self.slider[row].value=max_df\n",
    "            \n",
    "            if(self.slider[row].value < min_df):\n",
    "                self.slider[row].value=min_df\n",
    "                \n",
    "            #print(self.slider[row].value)\n",
    "            df_mask=self.not_stand_df[selection_as_list[row]]>=self.slider[row].value\n",
    "            temp=self.not_stand_df\n",
    "            \n",
    "            if(len(temp[df_mask])==0):\n",
    "                print(\"selection false,max min for this feature in this combination is: or change other targets\")\n",
    "            else:\n",
    "                temp = self.not_stand_df[df_mask]\n",
    "                self.idx = temp[df_mask].index\n",
    "                #print(\"len idx in on slider change\",len(self.idx))\n",
    "                #print(len(self.not_stand_df)==len(self.idx))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = targets(box_targets,target_selection) \n",
    "ft = fixed_targets(box_fixed_targets,fixed_target_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class sequential_learning:\n",
    "    \n",
    "    xlabel=\"Sequential Learning Iteration\"\n",
    "    dataframe = df_converter()\n",
    "    features_df=df_converter()\n",
    "    target_df=df_converter()\n",
    "    \n",
    "    min_distances_list=[]\n",
    "    \n",
    "    y_pred_dtr_mean=None\n",
    "    y_pred_dtr_std=None\n",
    "    y_pred_dtr=None\n",
    "    SampIdx=None\n",
    "    PredIdx=None\n",
    "    treshIdx=None\n",
    "    \n",
    "    index_sum_randomized=None\n",
    "    rand_tars=[]\n",
    "    rand_fixed_tars=[]\n",
    "   \n",
    "    def __init__(self,dataframe,init_sample_size,target_treshhold,\n",
    "                 number_of_executions,sigma,distance,\n",
    "                 model,strategy,targets_idx,fixed_targets_idx):  #constructor\n",
    "        \n",
    "        self.dataframe= dataframe\n",
    "        self.init_sample_size=init_sample_size\n",
    "        self.target_treshhold = target_treshhold/100\n",
    "        self.number_of_executions=number_of_executions\n",
    "        self.tries_list=np.empty(number_of_executions)\n",
    "        self.tries_list_rand_pick=np.empty(number_of_executions)\n",
    "        self.sigma=sigma\n",
    "        self.distance=distance\n",
    "        self.model=model\n",
    "        self.strategy = strategy\n",
    "        self.targets_idx=targets_idx\n",
    "        self.fixed_targets_idx=fixed_targets_idx\n",
    "        \n",
    "        \n",
    "        \n",
    "    def apply_feature_selection_to_df(self,dataframe):\n",
    "        self.features_df = self.dataframe[confirm_features()]    \n",
    "    \n",
    "    def apply_target_selection_to_df(self,dataframe):\n",
    "        self.target_df= self.dataframe[confirm_target()]    \n",
    "\n",
    "    #self werte return macht wenig sinn\n",
    "    def standardize_data(self):\n",
    "        dataframe_norm=(self.dataframe-self.dataframe.mean())/self.dataframe.std()\n",
    "        target_df_norm=(self.target_df-self.target_df.mean())/self.target_df.std()\n",
    "        features_df_norm=(self.features_df-self.features_df.mean())/self.features_df.std()\n",
    "        self.features_df=features_df_norm\n",
    "        self.target_df=target_df_norm\n",
    "        self.dataframe=dataframe_norm\n",
    "        return self.features_df, self.target_df, self.dataframe\n",
    "        \n",
    "\n",
    "\n",
    "    def init_sampling(self):\n",
    "        \n",
    "        targets = confirm_target()\n",
    "        fixed_targets=confirm_fixed_target()\n",
    "        df_unnorm=df_converter()\n",
    "        df=(df_unnorm-df_unnorm.mean())/(df_unnorm.std())\n",
    "        \n",
    "        sum_ = self.dataframe[targets].sum(axis=1).to_frame()+self.dataframe[fixed_targets].sum(axis=1).to_frame()\n",
    "        targ_q = quantile_tar_slider.value/100\n",
    "        \n",
    "        \n",
    "        if(t.idx is not None and ft.idx is not None):\n",
    "                treshholded_idx=t.idx.union(ft.idx)\n",
    "                \n",
    "        if(ft.idx is None ):\n",
    "                treshholded_idx=t.idx\n",
    "        else:\n",
    "                treshholded_idx=ft.idx\n",
    "                \n",
    "        checked_targets=[]\n",
    "        \n",
    "                \n",
    "        if(treshholded_idx is not None):\n",
    "                    \n",
    "                    for row in range(len(t.checkboxes)) :\n",
    "                        \n",
    "                        if (t.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(t.radiobuttons[row].description)\n",
    "                    \n",
    "                    for row in range(len(ft.checkboxes)):\n",
    "                        if (ft.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(ft.radiobuttons[row].description)\n",
    "                            \n",
    "                    sum_without_checked_targets=df.drop(columns=checked_targets).sum(axis=1).iloc[treshholded_idx]\n",
    "                    targ_q_t= sum_without_checked_targets.quantile(targ_q)\n",
    "                    Index_samp=np.where(sum_without_checked_targets < targ_q_t )\n",
    "                    Index_samp=Index_samp[0]\n",
    "        else:\n",
    "           \n",
    "            targ_q_t=sum_.quantile(targ_q)\n",
    "            Index_samp=np.where(sum_ >= targ_q_t )\n",
    "            Index_samp=Index_samp[0]\n",
    "        \n",
    "        init_sample_set = np.ones((0,self.init_sample_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    init_sample_set=np.vstack([init_sample_set, random.choice(Index_samp,self.init_sample_size)])\n",
    "\n",
    "        return init_sample_set\n",
    "                                         \n",
    "    def start_sequential_learning(self):\n",
    "            print(\"SL Startetd\")\n",
    "            self.tries_list=np.empty(self.number_of_executions)\n",
    "            self.tries_list.fill(np.nan)\n",
    "            self.tries_list_rand_pick=np.empty(self.number_of_executions)\n",
    "            self.tries_list_rand_pick.fill(np.nan)\n",
    "            self.count=0\n",
    "            \n",
    "            distances=[]\n",
    "            targt_perfs=[]\n",
    "            \n",
    "            fixed_targets=[]\n",
    "            targets=[]\n",
    "            \n",
    "            current_distances_list=[]   \n",
    "            current_targt_perf_list=[]\n",
    "            \n",
    "            \n",
    "            with out_perform_experiment:\n",
    "                    display(Markdown('Sequential Learning is running...'))\n",
    "\n",
    "\n",
    "            \n",
    "            global result_df   \n",
    "            \n",
    "            decide_max_or_min(box_targets,confirm_target(),self.dataframe)\n",
    "            decide_max_or_min(box_fixed_targets,confirm_fixed_target(),self.dataframe)\n",
    "            \n",
    "            \n",
    "            init_sample_set=self.init_sampling()\n",
    "            fixed_targets_index=confirm_fixed_target()\n",
    "            \n",
    "            \n",
    "            sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()+self.dataframe[fixed_targets_index].sum(axis=1).to_frame()\n",
    "            \n",
    "            targ_q_t= sum_.quantile(self.target_treshhold) \n",
    "            schwellwert=sum_.quantile(self.target_treshhold)\n",
    "            Index_c=np.where(sum_ >= schwellwert )\n",
    "            Index_c=Index_c[0]\n",
    "\n",
    "            for i in range(self.number_of_executions):\n",
    "                    \n",
    "                    self.perform_random_pick(i)\n",
    "                    self.SampIdx=init_sample_set[i].astype(int)\n",
    "                    self.PredIdx=self.dataframe\n",
    "                    self.PredIdx = self.PredIdx.drop(self.PredIdx.index[self.SampIdx]).index\n",
    "                    self.decide_model(self.model)\n",
    "                    self.tries_list[i]=self.init_sample_size\n",
    "                    distance=distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                    \n",
    "                    distance=distance.min()\n",
    "                    current_distances_list=[distance]\n",
    "                    \n",
    "                    #max value summe\n",
    "                    targt_perf=sum_.loc[self.SampIdx].max().item()\n",
    "                    current_targt_perf_list=[targt_perf] \n",
    "\n",
    "                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                    \n",
    "                    \n",
    "                    current_fixed_target_list=np.array(best_value[confirm_fixed_target()].to_numpy()[0])\n",
    "                    current_prediction_target=np.array(best_value[confirm_target()].to_numpy()[0])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    while np.any(np.in1d(self.SampIdx,self.treshIdx ))== False:\n",
    "                        \n",
    "                                    print(\"len(self.SampIdx\",len(self.SampIdx),\"len(self.self.treshIdx )\",len(self.treshIdx ))\n",
    "                                    print(type(self.SampIdx),type(self.treshIdx ))\n",
    "                                    self.update_strategy(self.strategy)\n",
    "\n",
    "                                    #Train Model\n",
    "                                    self.decide_model(self.model)\n",
    "\n",
    "                                    schwellwert=sum_.quantile(self.target_treshhold)\n",
    "                                    Index_c=np.where(sum_ >= schwellwert )\n",
    "                                    Index_c=Index_c[0]\n",
    "                                    \n",
    "                                    distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_c])\n",
    "                                    distance=distance.min()\n",
    "                                    current_distances_list.append(distance)\n",
    "\n",
    "                                    targt_perf=sum_.loc[self.SampIdx].max().values.tolist()\n",
    "                                    targt_perf=max(targt_perf)\n",
    "\n",
    "                                    current_targt_perf_list.append(targt_perf)\n",
    "                                    \n",
    "                                    \n",
    "                                    max_targt_perf_index=np.argmax(sum_.loc[self.SampIdx].values, axis=0)\n",
    "                                    Idx_of_best_value=self.SampIdx[max_targt_perf_index]\n",
    "                                    best_value=df_converter().iloc[Idx_of_best_value]\n",
    "                                    \n",
    "                                    current_prediction_target=np.vstack([current_prediction_target,best_value[confirm_target()].to_numpy()[0]])\n",
    "                                    current_fixed_target_list=np.vstack([current_fixed_target_list,best_value[confirm_fixed_target()].to_numpy()[0]])\n",
    "                                    \n",
    "        \n",
    "                                    self.tries_list[i]=self.tries_list[i]+1   \n",
    "\n",
    "                    distances.append(current_distances_list)\n",
    "                    targt_perfs.append(current_targt_perf_list)\n",
    "                    fixed_targets.append(current_fixed_target_list)\n",
    "                    targets.append(current_prediction_target)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                ##Distance Plot\n",
    "                \n",
    "                    with out_perform_experiment:\n",
    "                        fig1,axs = plt.subplots(1,2,figsize=(15, 6))\n",
    "                        axs[0].set_title('Optimization progress in input space')\n",
    "                        axs[0].set_xlabel('development cycles')\n",
    "                        axs[0].set_ylabel(\"Minimum distance from sampled data to target\")\n",
    "                        axs[0].axhline(y=0, color='k', linestyle=':',label='Target')\n",
    "                        axs[0].legend()\n",
    "\n",
    "                        axs[1].set_title('Optimization progress in output space')\n",
    "                        axs[1].set_xlabel('development cycles')\n",
    "                        axs[1].set_ylabel(\"Maximum sampled property\")\n",
    "                        axs[1].axhline(y=targ_q_t.values, color='k', linestyle=':',label='Target (normalized)')\n",
    "                        axs[1].legend()\n",
    "\n",
    "                    \n",
    "                        #Plotting\n",
    "                        for runs in range(len(distances)):\n",
    "                            axs[0].plot(distances[runs],linewidth=8, alpha=0.4)\n",
    "\n",
    "                    for runs in range(len(targt_perfs)):\n",
    "                        axs[1].plot(targt_perfs[runs],linewidth=8, alpha=0.4)\n",
    "                       \n",
    "                                    \n",
    "                        \n",
    "                    with out_perform_experiment:\n",
    "                            out_perform_experiment.clear_output(wait=True)\n",
    "                            time.sleep(1.0)\n",
    "                            fig2=plt.figure(figsize=(15, 5))\n",
    "                            plt.xlabel('Number of required Experiments')\n",
    "                            plt.ylabel(\"Frequency\")\n",
    "                            plt.title(\"Performance histogram for %s with strategy %s \"%(self.model,self.strategy))\n",
    "                            #plt.hist([self.tries_list,self.tries_list_rand_pick],bins=len(self.tries_list),label=['SL Tries', 'Random Pick Tries'])         \n",
    "                            plt.hist([self.tries_list_rand_pick],range=(1, len(self.features_df)),label=['Random Process'],alpha=0.4)         \n",
    "                            plt.hist([self.tries_list],label=['SL'],range=(1, len(self.features_df)),alpha=0.4)         \n",
    "                            plt.legend()\n",
    "\n",
    "                            plt.show()\n",
    "                            #plt.close(fig2)\n",
    "                            \n",
    "                            \n",
    "        #Extend values of perfs\n",
    "            lengths_of_perfs=[]\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                            current_len_of_perf=len(targt_perfs[runs])\n",
    "                            lengths_of_perfs.append(current_len_of_perf)\n",
    "\n",
    "            for runs in range(len(targt_perfs)):\n",
    "                                    if(len(targt_perfs[runs])!=max(lengths_of_perfs)):\n",
    "                                        size_of_values_to_add =max(lengths_of_perfs)-len(targt_perfs[runs])\n",
    "                                        targt_perfs[runs].extend(np.full(size_of_values_to_add, max(targt_perfs[runs])))\n",
    "\n",
    "            targt_perfs_as_array=np.array(targt_perfs)\n",
    "            mean_performances=np.mean(targt_perfs_as_array,axis=0)\n",
    "            \n",
    "            rel_perform_after_5=1.0\n",
    "            rel_perform_after_10=1.0\n",
    "            \n",
    "            max_performance=np.max(sum_)\n",
    "            \n",
    "            min_performance=np.min(sum_)\n",
    "        \n",
    "            \n",
    "            print(len(mean_performances))\n",
    "            \n",
    "            if(len(mean_performances) > 5 and len(mean_performances) <10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)==5):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                \n",
    "            if(len(mean_performances)>=10):\n",
    "                perform_after_5=mean_performances[4]\n",
    "                perform_after_10=mean_performances[9]\n",
    "                print(perform_after_10/max_performance)\n",
    "                rel_perform_after_5=(perform_after_5-min_performance)/(max_performance-min_performance)\n",
    "                rel_perform_after_10=(perform_after_10-min_performance)/(max_performance-min_performance)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if self.strategy=='MEI (exploit)':\n",
    "                self.sigma=0\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MU (explore)':\n",
    "                self.sigma=1\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MLI (explore & exploit)':\n",
    "                self.distance=0\n",
    "            elif self.strategy=='MEID (exploit)':\n",
    "                self.sigma=0\n",
    "            \n",
    "                \n",
    "            ##Appending Performance intensiv --> List comprehension\n",
    "            to_append=([np.mean(self.tries_list),np.std(self.tries_list),np.quantile(self.tries_list,0.90),\n",
    "                        np.quantile(self.tries_list,1),self.model, self.strategy,self.sigma,rel_perform_after_5,rel_perform_after_10,self.distance,\n",
    "                        self.number_of_executions,self.init_sample_size,len(self.dataframe.index),len(confirm_features()),\n",
    "                        len(confirm_target()),self.target_treshhold,\n",
    "                        confirm_features().tolist(),confirm_target().tolist(),self.tries_list])\n",
    "\n",
    "####SL-Results\n",
    "            with out_results_SL: \n",
    "                    out_results_SL.clear_output(wait=True)\n",
    "                    display(Markdown('### Performance summary:'))\n",
    "                    display(Markdown('requ. experiments with optimzation (mean):  {} '.format(\n",
    "                    np.mean(self.tries_list))))\n",
    "                    display(Markdown(\"requ. experiments without optimzation (mean): {}\".format(np.mean(self.tries_list_rand_pick))))\n",
    "                    display(Markdown(\" \"))\n",
    "                    display(Markdown('### Result plots:'))\n",
    "\n",
    "\n",
    "#Plot targets\n",
    "### Fixed Targets\n",
    "            if(len(confirm_fixed_target().values.tolist())>0):\n",
    "                    anzahl_plots=len(fixed_target_selection.value)\n",
    "                    fig3,axs_fixed = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots),squeeze=False)\n",
    "                    axs_fixed=axs_fixed.flatten()\n",
    "                    \n",
    "                    fixed_targets_extended=extend(fixed_targets)\n",
    "                    \n",
    "                    mean_fixed_targets_extended=np.mean(fixed_targets_extended,axis=0)\n",
    "                \n",
    "                    \n",
    "                    fixed_rand_extended=extend(self.rand_fixed_tars)\n",
    "                    \n",
    "                    mean_fixed_rand_extended=np.mean(fixed_rand_extended,axis=0)\n",
    "                    \n",
    "#Plot fixed targets\n",
    "                    for fixed_target in range(anzahl_plots):\n",
    "                            axs_fixed[fixed_target].set_title('Created value for %s'%(confirm_fixed_target()[fixed_target]))\n",
    "                            axs_fixed[fixed_target].set_xlabel('development cycles')\n",
    "                            axs_fixed[fixed_target].set_ylabel(\"Best sampled property\")\n",
    "                            axs_fixed[fixed_target].set_xlim([0,len(mean_fixed_targets_extended[:,0])])\n",
    "\n",
    "                    for one_tar in range(anzahl_plots):  \n",
    "       \n",
    "                        axs_fixed[one_tar].plot(mean_fixed_targets_extended[:,one_tar],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                        axs_fixed[one_tar].plot(mean_fixed_rand_extended[:,one_tar],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                        axs_fixed[one_tar].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average SL cycles to success')\n",
    "                        axs_fixed[one_tar].legend()\n",
    "                        \n",
    "                    for sl_run in range(len(targets)):                            \n",
    "                            for one_tar in range(anzahl_plots):\n",
    "                                        axs_fixed[one_tar].plot(fixed_targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')\n",
    "                                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "            with out_results_SL:\n",
    "                anzahl_plots=len(target_selection.value)\n",
    "                fig4,axs_pred = plt.subplots(anzahl_plots,figsize=(8,5*anzahl_plots), squeeze=False)\n",
    "                axs_pred=axs_pred.flatten()\n",
    "                targets_extended=extend(targets)\n",
    "                mean_targets_extended=np.mean(targets_extended,axis=0)\n",
    "                rand_extended=extend(self.rand_tars)\n",
    "                mean_rand_extended=np.mean(rand_extended,axis=0)\n",
    "                \n",
    "                \n",
    "                for pred_target in range(anzahl_plots):\n",
    "                            axs_pred[pred_target].set_title('Created value for %s'%(confirm_target()[pred_target]))\n",
    "                            axs_pred[pred_target].set_xlabel('development cycles')\n",
    "                            axs_pred[pred_target].set_ylabel(\"Best sampled property\")\n",
    "                            axs_pred[pred_target].set_xlim([0,len(mean_targets_extended[:,0])])\n",
    "\n",
    "                           \n",
    "                for pred_target in range(anzahl_plots):  \n",
    "    \n",
    "                        axs_pred[pred_target].plot(mean_targets_extended[:,pred_target],linewidth=8, alpha=0.9, color='k',label='With optimization')\n",
    "                        axs_pred[pred_target].plot(mean_rand_extended[:,pred_target],linewidth=8, alpha=0.9, color='g',label='Without optimization')\n",
    "                        axs_pred[pred_target].axvline(x=round(np.mean(self.tries_list)-self.init_sample_size), color='k', linestyle=':',label='Average SL cycles to success')\n",
    "                        axs_pred[pred_target].legend()\n",
    "                        \n",
    "               \n",
    "                for sl_run in range(len(targets)):                            \n",
    "                            for one_tar in range(anzahl_plots):\n",
    "                                        axs_pred[one_tar].plot(targets[sl_run][:,one_tar],linewidth=2, alpha=0.1,color='k')      \n",
    "                                        plt.xlim([0,len(mean_targets_extended[:,one_tar])])\n",
    "                \n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "\n",
    "    \n",
    "    \n",
    "            with out_results_SL:\n",
    "                    \n",
    "                    display(Markdown(\" \"))\n",
    "                    display(Markdown('### History:'))\n",
    "                    display(Markdown(\" \"))\n",
    "                    a_series = pd.Series(to_append, index = result_df.columns)\n",
    "                    result_df= result_df.append(a_series, ignore_index=True)\n",
    "                    display(Markdown(result_df.to_markdown()))\n",
    "                    display((create_download_link(result_df,'Download history','results_sl')))\n",
    "\n",
    "                    \n",
    "            \n",
    "            ###a\n",
    "            with out_perform_experiment:\n",
    "                        display(Markdown('done ✅'))\n",
    "                        display(Markdown(\" \"))\n",
    "                        \n",
    "            \n",
    "            \n",
    "                           \n",
    "    def perform_random_pick(self,acutal_iter):\n",
    "        sum_ = self.dataframe[confirm_target()].sum(axis=1).to_frame()+self.dataframe[confirm_fixed_target()].sum(axis=1).to_frame()\n",
    "        index_sum=sum_.index.to_numpy()\n",
    "        index_sum_randomized=np.random.choice(index_sum,len(index_sum),False)\n",
    "        targ_q_t= sum_.quantile(self.target_treshhold)\n",
    "        self.tries_list_rand_pick[acutal_iter]=1\n",
    "\n",
    "        \n",
    "        run=0\n",
    "        \n",
    "        best_value=df_converter().iloc[index_sum_randomized[run]]\n",
    "        \n",
    "        current_fixed_rand_tars=np.array(best_value[confirm_fixed_target()].to_numpy())\n",
    "        current_pred_rand_tars=np.array(best_value[confirm_target()].to_numpy())\n",
    "        \n",
    "        \n",
    "        \n",
    "        while sum_.iloc[index_sum_randomized[run]].values[0].astype(float).item() < targ_q_t.item():\n",
    "            self.tries_list_rand_pick[acutal_iter]=self.tries_list_rand_pick[acutal_iter]+1 \n",
    "            \n",
    "            \n",
    "            temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "            max_index=index_sum_randomized[temp_index]\n",
    "            best_value=df_converter().iloc[max_index]\n",
    "            current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target()].to_numpy()])\n",
    "            current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target()].to_numpy()])\n",
    "            run=run+1\n",
    "        \n",
    "        temp_index=np.argmax(sum_.iloc[index_sum_randomized[0:run+1]]) \n",
    "        max_index=index_sum_randomized[temp_index]\n",
    "        best_value=df_converter().iloc[max_index]\n",
    "        current_pred_rand_tars=np.vstack([current_pred_rand_tars,best_value[confirm_target()].to_numpy()])\n",
    "        current_fixed_rand_tars=np.vstack([current_fixed_rand_tars,best_value[confirm_fixed_target()].to_numpy()])\n",
    "        \n",
    "        self.rand_fixed_tars.append(current_fixed_rand_tars)\n",
    "        self.rand_tars.append(current_pred_rand_tars)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #Refactor idee: Model klasse mit name und checkbox description\n",
    "    def decide_model(self,model):\n",
    "        if model== 'lolo Random Forrest (RF) - quick (requ. min 8 init. samples)':\n",
    "                    Expected_Pred, Uncertainty=  self.fit_RF_wJK()\n",
    "        elif model == 'Decision Trees (DT) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_DT_wJK()\n",
    "        elif model == 'Random Forrest (RFscikit) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_TE_wJK()\n",
    "        elif model == 'Gaussian Process Regression (GPR) - quick':\n",
    "                    Expected_Pred, Uncertainty =  self.fit_GP()\n",
    "                    \n",
    "            \n",
    "    def update_strategy(self, strategy):\n",
    "        if strategy=='MEI (exploit)':\n",
    "            self.updateIndexMEI()\n",
    "        elif strategy=='MU (explore)':\n",
    "            self.updateIndexMU()\n",
    "        elif strategy=='MLI (explore & exploit)':\n",
    "            self.updateIndexMLI()\n",
    "        elif strategy=='MEID (exploit)':\n",
    "            self.updateIndexMEID()        \n",
    "        elif strategy=='MLID (explore & exploit)':\n",
    "            self.updateIndexMLID()\n",
    "        \n",
    "    \n",
    "    def updateIndexMEI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze())\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMEID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            schwellwert=np.quantile(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze(),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            \n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "\n",
    " \n",
    "\n",
    "    def updateIndexMLID(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            schwellwert=np.quantile((fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()),self.distance/100)\n",
    "            Index_=np.where(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze()>=schwellwert )\n",
    "            Index_=Index_[0]\n",
    "            distance= distance_matrix(self.dataframe.loc[self.SampIdx],self.dataframe.iloc[Index_])\n",
    "            min_distances=distance.min(0)\n",
    "            result = np.where(distance == min_distances.max())\n",
    "            # zip the 2 arrays to get the exact coordinates\n",
    "            listOfCordinates = list(zip(result[0], result[1]))    \n",
    "            index_max=Index_[result[1]]\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx              \n",
    "            \n",
    "            \n",
    "    def updateIndexMU(self):\n",
    "            index_max = np.argmax(self.Uncertainty)\n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "            \n",
    "            \n",
    "    def updateIndexMLI(self):\n",
    "            fixed_targets_in_prediction=self.dataframe[confirm_fixed_target()].iloc[self.PredIdx].sum(axis=1).to_frame()\n",
    "            index_max = np.argmax(fixed_targets_in_prediction.squeeze()+self.Expected_Pred.squeeze()+self.sigma*self.Uncertainty.squeeze())    \n",
    "            new_SampIdx=np.append(self.SampIdx,self.PredIdx[index_max])\n",
    "            self.SampIdx=new_SampIdx\n",
    "            new_PredIdx = np.delete(self.PredIdx, index_max)\n",
    "            self.PredIdx=new_PredIdx\n",
    "                        \n",
    "            \n",
    "    def fit_DT_wJK(self):        \n",
    "        print(\"len(self.features_df.iloc[self.PredIdx])\",len(self.features_df.iloc[self.PredIdx]))\n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            dtr = DecisionTreeRegressor()\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "        \n",
    "       \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "        \n",
    "    def fit_TE_wJK(self):\n",
    "        td,tl=self.jk_resampling()\n",
    "        self.y_pred_dtr=[]\n",
    "        for i in range(len(td)):\n",
    "            ## alternative Ensamble Learners below:\n",
    "            dtr = SKRFR (n_estimators=10)\n",
    "            #dtr =AdaBoostRegressor(n_estimators = 10)\n",
    "            dtr.fit(td[i], tl[i])\n",
    "            self.y_pred_dtr.append(dtr.predict(self.features_df.iloc[self.PredIdx]))\n",
    "                \n",
    "        \n",
    "        #quick bug fix\n",
    "        if(self.strategy==\"MEID (exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        elif(self.strategy==\"MLID (explore & exploit)\"):\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=0)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=0)\n",
    "        else:\n",
    "            self.y_pred_dtr=np.array(self.y_pred_dtr)\n",
    "            self.y_pred_dtr=self.y_pred_dtr.T\n",
    "            self.Expected_Pred = self.y_pred_dtr.mean(axis=1)\n",
    "            self.Uncertainty = self.y_pred_dtr.std(axis=1)\n",
    "\n",
    "\n",
    "        return self.Expected_Pred, self.Uncertainty        \n",
    "\n",
    "    def jk_resampling(self):\n",
    "        from resample.jackknife import resample as b_resample\n",
    "        td=[x for x in b_resample(self.features_df.iloc[self.SampIdx])]\n",
    "        tl=[x for x in b_resample(self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame())]\n",
    "        td=np.array(td)\n",
    "        tl=np.array(tl)\n",
    "        return td,tl\n",
    "                   \n",
    "    def fit_RF_wJK(self):\n",
    "        dtr = RandomForestRegressor()\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty = dtr.predict(self.features_df.iloc[self.PredIdx].to_numpy(), return_std=True)\n",
    "        return self.Expected_Pred, self.Uncertainty\n",
    "    \n",
    "    def fit_GP(self):\n",
    "        \n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "        dtr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "        dtr.fit(self.features_df.iloc[self.SampIdx].to_numpy(), self.dataframe[confirm_target()].iloc[self.SampIdx].sum(axis=1).to_frame().to_numpy())\n",
    "        self.Expected_Pred, self.Uncertainty= dtr.predict(self.features_df.iloc[self.PredIdx], return_std=True)      \n",
    "        return self.Expected_Pred.squeeze(), self.Uncertainty.squeeze()\n",
    "\n",
    "    \n",
    "    \n",
    "    def plot_TSNE_input_space(self):\n",
    "    \n",
    "            from sklearn.manifold import TSNE\n",
    "            \n",
    "        \n",
    "            if(t.idx is not None and ft.idx is not None):\n",
    "                treshholded_idx=t.idx.union(ft.idx)\n",
    "                \n",
    "            if(ft.idx is None ):\n",
    "                treshholded_idx=t.idx\n",
    "            else:\n",
    "                treshholded_idx=ft.idx\n",
    "            \n",
    "            \n",
    "            \n",
    "            features_df=(df_converter()[confirm_features()]-df_converter()[confirm_features()].mean())/df_converter()[confirm_features()].std()\n",
    "            target_df=(df_converter()[confirm_target()]-df_converter()[confirm_target()].mean())/df_converter()[confirm_target()].std()       \n",
    "            fixed_target_df=(df_converter()[confirm_fixed_target()]-df_converter()[confirm_fixed_target()].mean())/df_converter()[confirm_fixed_target()].std()               \n",
    "            df_unnorm=df_converter()\n",
    "            df=(df_unnorm-df_unnorm.mean())/(df_unnorm.std())\n",
    "        \n",
    "            \n",
    "            decide_max_or_min(box_targets,confirm_target(),target_df)\n",
    "            decide_max_or_min(box_fixed_targets,confirm_fixed_target(),fixed_target_df)\n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            with out_input_space:\n",
    "                # Plot Results in reduced FS\n",
    "                out_input_space.clear_output(wait=True)\n",
    "                fig3= plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "                \n",
    "                \n",
    "                checked_targets=[]\n",
    "                \n",
    "                if(treshholded_idx is not None):\n",
    "                    \n",
    "                    for row in range(len(t.checkboxes)) :\n",
    "                        \n",
    "                        if (t.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(t.radiobuttons[row].description)\n",
    "                    \n",
    "                    for row in range(len(ft.checkboxes)):\n",
    "                        if (ft.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(ft.radiobuttons[row].description)\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                    sum_without_checked_targets=df.drop(columns=checked_targets).sum(axis=1).iloc[treshholded_idx]\n",
    "                    targ_q = quantile_tar_slider.value/100\n",
    "                    targ_q_t= sum_without_checked_targets.quantile(targ_q)\n",
    "                    Index_c=np.where(sum_without_checked_targets >= targ_q_t )\n",
    "                    Index_c=Index_c[0]\n",
    "                    sum_.iloc[Index_c]=sum_.iloc[Index_c]+100000000\n",
    "                    \n",
    "                    \n",
    "                    Index_samp=np.where(sum_without_checked_targets < targ_q_t )\n",
    "                    Index_samp=Index_samp[0]\n",
    "                   \n",
    "            \n",
    "                tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300,random_state=1000)\n",
    "                tsne_results = tsne.fit_transform(features_df)\n",
    "                \n",
    "\n",
    "                    \n",
    "                \n",
    "                cmap = plt.get_cmap('cool', 200)\n",
    "                cmap.set_over('lawngreen')\n",
    "                \n",
    "                if(treshholded_idx is None):\n",
    "                    targ_q = quantile_tar_slider.value/100\n",
    "                    \n",
    "                    \n",
    "                    targ_q_t= sum_.quantile(targ_q)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=targ_q_t.values-0.0001)\n",
    "                    \n",
    "                else:\n",
    "                    exclude=treshholded_idx\n",
    "                    \n",
    "                    \n",
    "                    if(len(exclude)==len(sum_)):\n",
    "                        max_of_features_without_targets=np.max(sum_)\n",
    "                    else:\n",
    "                        samples_without_target_idx=np.delete(sum_.to_numpy(), exclude)\n",
    "                        max_of_features_without_targets=np.max(samples_without_target_idx)\n",
    "                        \n",
    "                    \n",
    "                    sc=plt.scatter(x=tsne_results[:,0],y=tsne_results[:,1], c=sum_, \n",
    "                                   cmap=cmap, vmax=np.max(sum_.iloc[Index_samp])+1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                cbar=plt.colorbar(sc,extend='both')\n",
    "                \n",
    "                cbar.ax.set_yticklabels([ ]) \n",
    "                cbar.ax.set_ylabel('targets (green)                normalized target property', rotation=270 ,va='center')\n",
    "\n",
    "                plt.title(\"Design space in TSNE-coordinates: candidate pool and targets\")\n",
    "                plt.show()\n",
    "                        \n",
    "                plt.close(fig3)\n",
    "        \n",
    "    def main(self):\n",
    "        self.apply_feature_selection_to_df(self.dataframe)\n",
    "        self.apply_target_selection_to_df(self.dataframe)\n",
    "        if(len(confirm_fixed_target().values.tolist())>0):\n",
    "            self.target_df=self.target_df.join(self.dataframe[confirm_fixed_target()])\n",
    "        self.standardize_data()\n",
    "        init_sample_set=self.init_sampling()\n",
    "        \n",
    "        \n",
    "        targ_q = quantile_tar_slider.value/100\n",
    "        \n",
    "        if(t.idx is not None and ft.idx is not None):\n",
    "                treshholded_idx=t.idx.union(ft.idx)\n",
    "                \n",
    "        if(ft.idx is None ):\n",
    "                treshholded_idx=t.idx\n",
    "        else:\n",
    "                treshholded_idx=ft.idx\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        features_df=(df_converter()[confirm_features()]-df_converter()[confirm_features()].mean())/df_converter()[confirm_features()].std()\n",
    "        target_df=(df_converter()[confirm_target()]-df_converter()[confirm_target()].mean())/df_converter()[confirm_target()].std()       \n",
    "        fixed_target_df=(df_converter()[confirm_fixed_target()]-df_converter()[confirm_fixed_target()].mean())/df_converter()[confirm_fixed_target()].std()               \n",
    "        df_unnorm=df_converter()\n",
    "        df=(df_unnorm-df_unnorm.mean())/(df_unnorm.std())\n",
    "        sum_ = target_df.sum(axis=1).to_frame()+fixed_target_df.sum(axis=1).to_frame()\n",
    "                \n",
    "                \n",
    "        checked_targets=[]\n",
    "                \n",
    "        if(treshholded_idx is not None):\n",
    "                    \n",
    "                for row in range(len(t.checkboxes)) :\n",
    "                        \n",
    "                        if (t.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(t.radiobuttons[row].description)\n",
    "                    \n",
    "                for row in range(len(ft.checkboxes)):\n",
    "                        if (ft.checkboxes[row].value == True):\n",
    "                            \n",
    "                            checked_targets.append(ft.radiobuttons[row].description)\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                sum_without_checked_targets=df.drop(columns=checked_targets).sum(axis=1).iloc[treshholded_idx]\n",
    "                targ_q = quantile_tar_slider.value/100\n",
    "                targ_q_t= sum_without_checked_targets.quantile(targ_q)\n",
    "                Index_c=np.where(sum_without_checked_targets >= targ_q_t )\n",
    "                self.treshIdx=Index_c[0]\n",
    "        else:\n",
    "            targ_q_t=sum_.quantile(targ_q)\n",
    "            Index_samp=np.where(sum_ >= targ_q_t )\n",
    "            self.treshIdx=Index_samp[0]\n",
    "        self.start_sequential_learning()\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s = sequential_learning(df_converter(),initial_sample_size_text.value,quantile_tar_slider.value,\n",
    "                        iterations.value,slider_of_for_std.value,\n",
    "                        slider_of_for_dist.value,select_model.value,confirm_strategy(),t.idx,\n",
    "                       ft.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_experiment_clicked(b):\n",
    "    start_and_stop_sl_container.children=[button_perform_experiment]\n",
    "    s = sequential_learning(df_converter(),initial_sample_size_text.value,quantile_tar_slider.value,\n",
    "                        iterations.value,slider_of_for_std.value,\n",
    "                        slider_of_for_dist.value,select_model.value,confirm_strategy(),t.idx,ft.idx)\n",
    "    \n",
    "    \n",
    "    s.main()\n",
    "    \n",
    "def plotterDS_clicked(b):\n",
    "    s.plot_TSNE_input_space()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_clicked(b):\n",
    "    try:\n",
    "        preview()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def upload_clicked(b):\n",
    "    if(up._counter>1):\n",
    "        up.value.clear()\n",
    "        up._counter = 1\n",
    "    try:\n",
    "        upload()\n",
    "    except pd.errors.ParserError:\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            display(Markdown(\"Sth. wennt wrong! Please check your csv and the upload settings\"))\n",
    "    \n",
    "def desc_clicked(b):\n",
    "    desc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_settings_button_clicked(b):\n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        display(Markdown(settings.to_markdown()))\n",
    "        \n",
    "def confirm_import_clicked(b):\n",
    "    if(import_button._counter>1):\n",
    "        up.value.clear()\n",
    "        import_button._counter=1\n",
    "    \n",
    "    settings = import_settings()\n",
    "    with out_settings:\n",
    "        out_settings.clear_output(wait=True)\n",
    "        display(Markdown('Your Settings got importet and look like:'))\n",
    "        display(Markdown(settings.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter_clicked(b):\n",
    "    plot()\n",
    "\n",
    "def pairwise_clicked(b):\n",
    "    plot_pairwise()\n",
    "def heat_clicked(b):\n",
    "    plot_heat()\n",
    "def scatter_clicked(b):\n",
    "    plot_scatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def on_strategy_changes(change):\n",
    "    if select_strategy.value==\"MEID (exploit)\":\n",
    "        create_slider_for_dist_quantile()\n",
    "    elif select_strategy.value==\"MLID (explore & exploit)\":  \n",
    "        create_slider_for_dist_quantile_std()\n",
    "    elif select_strategy.value==\"MLI (explore & exploit)\":\n",
    "        create_slider_for_std()\n",
    "        \n",
    "def display_progess_automation(actual_iter,all_comb):\n",
    "    with out_iter_aut:\n",
    "            time.sleep(0.1)\n",
    "            out_iter_aut.clear_output()\n",
    "            display(Markdown('\\n Status  {}/{} \\n'.format(\n",
    "                        actual_iter+1,all_comb)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confirm_features_clicked(b):\n",
    "    confirm_features()\n",
    "    \n",
    "def on_feature_selection_change(change):\n",
    "    confirm_features()\n",
    "    \n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]\n",
    "\n",
    "\n",
    "def confirm_var_clicked(b):\n",
    "    confirm_var()\n",
    "\n",
    "def confirm_options_clicked(b):\n",
    "    confirm_options()\n",
    "\n",
    "def confirm_strategy_clicked(b):\n",
    "    confirm_strategy()\n",
    "    \n",
    "    \n",
    "def on_graph_type_change(change):\n",
    "        \n",
    "    if graph_type.value ==\"Scatter\":\n",
    "        container_plot_options.children= [HBox([select_x,select_y]),\n",
    "        HBox([select_hue,select_size])]\n",
    "    elif graph_type.value ==\"Scatter Matrix\":\n",
    "        \n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "                                          \n",
    "    elif graph_type.value =='Correlation Heatmap':\n",
    "        container_plot_options.children= [HBox([selector_plot_variable,button_confirm_plot_var])]\n",
    "        \n",
    "    else: container_plot_options.children=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "button_upload.on_click(upload_clicked)\n",
    "toggle.observe(desc_clicked, 'value')\n",
    "button_preview.on_click(preview_clicked)\n",
    "\n",
    "button_confirm_plot_var.on_click(confirm_var_clicked)\n",
    "\n",
    "feature_selector.observe(on_feature_selection_change,names='value')\n",
    "target_selection.observe(t.on_selection_change,names='value')\n",
    "fixed_target_selection.observe(ft.on_selection_change,names='value')\n",
    "\n",
    "\n",
    "graph_type.observe(on_graph_type_change,names='value')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_strategy.observe(on_strategy_changes,names=\"value\")\n",
    "\n",
    "button_confirm_options.on_click(confirm_options_clicked)\n",
    "button_confirm_strategy.on_click(confirm_strategy_clicked)\n",
    "\n",
    "preview_settings_button.on_click(preview_settings_button_clicked) \n",
    "button_perform_experiment.on_click(perform_experiment_clicked)\n",
    "confirm_import_button.on_click(confirm_import_clicked)\n",
    "\n",
    "button_plot.on_click(plotter_clicked)\n",
    "button_show_DS.on_click(confirm_target,confirm_fixed_target)\n",
    "button_show_DS.on_click(plotterDS_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63357bd843914a9791db04d644a90241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Accordion(children=(FileUpload(value={}, description='Upload'), HBox(children=(Ra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SL Startetd\n",
      "len(self.features_df.iloc[self.PredIdx]) 155\n",
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-20b112ddc3d7>\u001b[0m in \u001b[0;36mperform_experiment_clicked\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplotterDS_clicked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7a944eec7eac>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mIndex_samp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtarg_q_t\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtreshIdx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIndex_samp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_sequential_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-7a944eec7eac>\u001b[0m in \u001b[0;36mstart_sequential_learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m                             \u001b[0maxs_fixed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixed_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'development cycles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                             \u001b[0maxs_fixed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixed_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best sampled property\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                             \u001b[0maxs_fixed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixed_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fixed_targets_extended\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mone_tar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manzahl_plots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
